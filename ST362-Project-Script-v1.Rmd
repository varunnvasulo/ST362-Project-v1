---
title: "Creation of Data"
output: pdf_document
date: "`r format(Sys.time(), '%a %b, %Y')`"
geometry: margin=1in
fontsize: 10pt
spacing: double
endnote: no
fig_width: 7
fig_height: 6
---

```{r, include=FALSE}
library(ggplot2)
library(dplyr)
library(dplyr)

```

### Loading in Data

```{r}
DATA <- read.csv("/Users/adamfarber/Desktop/2022-2023 NBA Player Stats - Regular.csv")
# 
DATA_NBA23<-DATA[c("Pos","PTS","MP","AST","TRB","STL","BLK","TOV","FG.","FT.","eFG.")]
```

Turning the Position variable into three categories.

```{r}
# Create a vector with the original positions
positions <- c("C", "PF", "PF-SF", "PG", "SF", "SF-SG", "SG", "SGPG")

# Create a function to categorize the positions
categorize_pos <- function(position) {
  if (position %in% c("PG","SG","SG-PG")) {
    return("G")
  } else if (position %in% c("SF", "PF", "PF-SF", "SF-SG")) {
    return("F")
  } else {
    return(position)
  }
}
DATA_NBA23$Pos <- sapply(DATA_NBA23$Pos, categorize_pos)
```

Effect of comning the postion varibale into G,F,C

```{R}
ggplot(DATA_NBA23) +
    aes(x = Pos, y = BLK) +
    geom_boxplot()

# For The categorical predictor position, AST and Blocks change a fair amount but the other predictors stay relatively even. 

#Lets see how combining the categorical predictor affected our variables
ggplot(DATA_NBA23) +
    aes(y = PTS , x = TOV , colour = Pos) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, formula = y ~ x)

```

#Creating a dummy variable for postion

```{R}
#In order to use our new position variable we need to make a dummy variable to include it into the model.
# Create the dummy variables
DATA_NBA23$Pos <- sapply(DATA_NBA23$Pos, categorize_pos)
dummy_variables <- model.matrix(~ Pos - 1, data = DATA_NBA23)
dummy_variables <- dummy_variables[, -1]
DATA_NBA23$Pos <- NULL
DATA_NBA23 <- cbind(DATA_NBA23, dummy_variables)
```

#create a new predictor correlated with another predictor

```{R}
correlation<-cor(DATA_NBA23)
#FG and eFG. are highly correlated variables with a cor. over .9. TOV and Assist are also highly correlated lets look at a some graphs to justify. 
ggplot(DATA_NBA23, aes(x = FG., y = eFG.)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 1) +
  labs(title = "Scatter Plot") +
  theme_minimal()
ggplot(DATA_NBA23, aes(x = TOV, y = AST)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 1) +
  labs(title = "Scatter Plot") +
  theme_minimal()
#we think it is justifiable to make the coefficient of eFG zero because having field goal in the model seems to be representative of its contribution to points.
Model<- lm(PTS~. - eFG. , data=DATA_NBA23)
Check_model<-summary(Model)
```

Polynomial?

```{R}
ggplot(DATA_NBA23, aes(x = MP, y = PTS)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 1) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "green", size = 1) +
  labs(title = "Scatter Plot of MPG and PTS",
       x = "MPG",
       y = "PTS") +
  theme_minimal()
#We can see by the plot it looks like we MPG is non-linear. The curved line looks a lot better then the strait red line. Lets add min played as a polynomial in the model.
Model<- lm(PTS~. - eFG. - MP + poly(MP,2), data=DATA_NBA23)
coefficients(Model)
```

#Now lets simulate a new response varibale

```{R}
DATA_NBA23$MP2 <- DATA_NBA23$MP^2
X <- as.matrix(DATA_NBA23[, c("AST", "TRB", "STL","BLK","TOV","FG.","FT.","PosF","PosG","MP","MP2")])
y <- as.matrix(DATA_NBA23[, "PTS"])
X <- cbind(1, X)
beta <- solve(t(X) %*% X) %*% t(X) %*% y
PTSNEW <- X %*% beta
PTSNEW <- X %*% beta
PTSNEW[PTSNEW < 0] <- 0

#lets see if our model predicted points well.
ggplot(DATA_NBA23, aes(x = PTS, y = PTSNEW)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 1) +
  labs(title = "Scatter Plot") +
  theme_minimal()
#looks like our mode did a good job at predicting points
```

#Finaly lets create our new DATA_NBA23 set

```{R}
DATA_NBA23$MP2<-NULL
DATA_NBA23$PosF<-NULL
DATA_NBA23$PosG<-NULL
DATA_NBA23$Pos <- sapply(DATA$Pos, categorize_pos)
DATA_NBA23$PTS <- PTSNEW
# Write the simulated_DATA_NBA23 DATA_NBA23 frame to a CSV file
write.csv(DATA_NBA23, "ST362_NBA23.csv", row.names = FALSE)
```
